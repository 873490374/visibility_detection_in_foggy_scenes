{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengxg/anaconda2/envs/zp_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from inception_v4 import inception_v4\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, AveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils import get_data, generate_generator, gen_img_paths_and_labels, SaveModelOnMSE_1, SaveModelOnMSE_2\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "net = 'inceptionV4'\n",
    "LOSS = 'MSE'\n",
    "idx_start, idx_end = 1, 3\n",
    "initial_model_dir = 'weights_new/imagenet_weights'\n",
    "initial_json_path = os.path.join(initial_model_dir, net+'.json')\n",
    "initial_hdf5_path = os.path.join(initial_model_dir, net+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_paths), len(train_labels): 55200 55200\n",
      "len(validate_paths), len(validate_labels): 100 100\n",
      "len(test_paths), len(test_labels): 12000 12000\n",
      "len(test_paths_real), len(test_labels_real): 199 199\n",
      "Training...\n",
      "epochs per iteration = 20\n",
      "Epoch 1/60\n",
      "173/173 [==============================] - 108s 625ms/step - loss: 19888.1834 - val_loss: 12237.8779\n",
      "Epoch 2/60\n",
      "173/173 [==============================] - 81s 466ms/step - loss: 16944.3251 - val_loss: 9496.5371\n",
      "Epoch 3/60\n",
      "173/173 [==============================] - 83s 481ms/step - loss: 15139.9691 - val_loss: 7147.3330\n",
      "Epoch 4/60\n",
      "173/173 [==============================] - 83s 480ms/step - loss: 12590.9474 - val_loss: 5405.2461\n",
      "Epoch 5/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 10447.6670 - val_loss: 784.3655\n",
      "Epoch 6/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 9379.4239 - val_loss: 4373.3916\n",
      "Epoch 7/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 7641.1186 - val_loss: 4936.4009\n",
      "Epoch 8/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 7040.1638 - val_loss: 5049.1914\n",
      "Epoch 9/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 5861.8783 - val_loss: 6444.5903\n",
      "Epoch 10/60\n",
      "173/173 [==============================] - 83s 482ms/step - loss: 4826.5804 - val_loss: 7394.0542\n",
      "Epoch 11/60\n",
      "173/173 [==============================] - 83s 481ms/step - loss: 4175.3834 - val_loss: 4140.5371\n",
      "Epoch 12/60\n",
      "173/173 [==============================] - 83s 482ms/step - loss: 3426.9735 - val_loss: 4299.9473\n",
      "Epoch 13/60\n",
      "173/173 [==============================] - 83s 480ms/step - loss: 2378.5152 - val_loss: 4094.2537\n",
      "Epoch 14/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 2311.8981 - val_loss: 5205.0957\n",
      "Epoch 15/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 1765.3731 - val_loss: 13480.1582\n",
      "Epoch 16/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 1604.1635 - val_loss: 490.2461\n",
      "Epoch 17/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 1072.5303 - val_loss: 610.9011\n",
      "Epoch 18/60\n",
      "173/173 [==============================] - 83s 477ms/step - loss: 835.3933 - val_loss: 322.1298\n",
      "Epoch 19/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 764.9746 - val_loss: 587.0930\n",
      "Epoch 20/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 636.0052 - val_loss: 1074.4012\n",
      "Epoch 21/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 502.0172 - val_loss: 1550.8977\n",
      "Epoch 22/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 405.8215 - val_loss: 1550.6554\n",
      "Epoch 23/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 400.8285 - val_loss: 2507.9294\n",
      "Epoch 24/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 285.7535 - val_loss: 940.6567\n",
      "Epoch 25/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 215.6688 - val_loss: 2300.1565\n",
      "Epoch 26/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 263.3043 - val_loss: 2824.4932\n",
      "Epoch 27/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 242.1773 - val_loss: 3414.7354\n",
      "Epoch 28/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 240.9265 - val_loss: 5431.2085\n",
      "Epoch 29/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 253.3290 - val_loss: 5219.6182\n",
      "Epoch 30/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 202.4885 - val_loss: 6227.2349\n",
      "Epoch 31/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 235.7658 - val_loss: 7963.4146\n",
      "Epoch 32/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 209.8765 - val_loss: 4049.2432\n",
      "Epoch 33/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 174.6025 - val_loss: 5089.2285\n",
      "Epoch 34/60\n",
      "173/173 [==============================] - 83s 477ms/step - loss: 237.5623 - val_loss: 5286.0444\n",
      "Epoch 35/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 220.8319 - val_loss: 3023.0493\n",
      "Epoch 36/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 187.7768 - val_loss: 3966.2441\n",
      "Epoch 37/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 185.4287 - val_loss: 4658.7134\n",
      "Epoch 38/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 168.8613 - val_loss: 3805.5020\n",
      "Epoch 39/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 198.3459 - val_loss: 1022.8517\n",
      "Epoch 40/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 172.6356 - val_loss: 4817.8442\n",
      "Epoch 41/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 154.7335 - val_loss: 5446.8047\n",
      "Epoch 42/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 150.2663 - val_loss: 6776.0532\n",
      "Epoch 43/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 156.5098 - val_loss: 7144.6704\n",
      "Epoch 44/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 155.0630 - val_loss: 4127.0518\n",
      "Epoch 45/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 114.4674 - val_loss: 6675.2407\n",
      "Epoch 46/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 141.5170 - val_loss: 7011.4536\n",
      "Epoch 47/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 151.9568 - val_loss: 7453.3789\n",
      "Epoch 48/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 142.2582 - val_loss: 6065.1230\n",
      "Epoch 49/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 121.1770 - val_loss: 6696.3076\n",
      "Epoch 50/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 111.9611 - val_loss: 5383.8237\n",
      "Epoch 51/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 157.0266 - val_loss: 4837.7646\n",
      "Epoch 52/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 138.9937 - val_loss: 6800.1938\n",
      "Epoch 53/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 131.2064 - val_loss: 6062.8154\n",
      "Epoch 54/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 135.5092 - val_loss: 3839.6189\n",
      "Epoch 55/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 130.0811 - val_loss: 4347.7207\n",
      "Epoch 56/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 105.1517 - val_loss: 3569.2751\n",
      "Epoch 57/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 114.0116 - val_loss: 5400.7744\n",
      "Epoch 58/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 116.2712 - val_loss: 6410.7974\n",
      "Epoch 59/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 117.2206 - val_loss: 5777.4199\n",
      "Epoch 60/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 123.0559 - val_loss: 6997.9663\n",
      "Epoch 1/60\n",
      "173/173 [==============================] - 106s 610ms/step - loss: 75.7982 - val_loss: 6627.6592\n",
      "Epoch 2/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 72.3959 - val_loss: 7043.4419\n",
      "Epoch 3/60\n",
      "173/173 [==============================] - 83s 479ms/step - loss: 87.4956 - val_loss: 7140.4790\n",
      "Epoch 4/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 69.2877 - val_loss: 6774.3398\n",
      "Epoch 5/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 61.0580 - val_loss: 6609.9238\n",
      "Epoch 6/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 75.8087 - val_loss: 7660.2412\n",
      "Epoch 7/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 54.5160 - val_loss: 7572.2700\n",
      "Epoch 8/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 64.8866 - val_loss: 7187.9961\n",
      "Epoch 9/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 63.6045 - val_loss: 7794.4644\n",
      "Epoch 10/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 52.7487 - val_loss: 7127.3779\n",
      "Epoch 11/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 62.8044 - val_loss: 7776.3101\n",
      "Epoch 12/60\n",
      "173/173 [==============================] - 83s 477ms/step - loss: 62.4464 - val_loss: 7702.3979\n",
      "Epoch 13/60\n",
      "173/173 [==============================] - 83s 477ms/step - loss: 61.8429 - val_loss: 7738.2148\n",
      "Epoch 14/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 83s 481ms/step - loss: 52.1801 - val_loss: 7862.0342\n",
      "Epoch 15/60\n",
      "173/173 [==============================] - 83s 478ms/step - loss: 53.9705 - val_loss: 7098.3828\n",
      "Epoch 16/60\n",
      "173/173 [==============================] - 82s 473ms/step - loss: 45.5736 - val_loss: 6719.6328\n",
      "Epoch 17/60\n",
      "173/173 [==============================] - 81s 469ms/step - loss: 45.7148 - val_loss: 7409.8311\n",
      "Epoch 18/60\n",
      "173/173 [==============================] - 81s 469ms/step - loss: 46.9712 - val_loss: 6917.4023\n",
      "Epoch 19/60\n",
      "173/173 [==============================] - 81s 470ms/step - loss: 44.6934 - val_loss: 6134.0903\n",
      "Epoch 20/60\n",
      "173/173 [==============================] - 81s 469ms/step - loss: 44.4796 - val_loss: 6155.1040\n",
      "Epoch 21/60\n",
      "173/173 [==============================] - 81s 466ms/step - loss: 50.6860 - val_loss: 6609.7852\n",
      "Epoch 22/60\n",
      "173/173 [==============================] - 81s 467ms/step - loss: 52.4234 - val_loss: 6806.4399\n",
      "Epoch 23/60\n",
      "173/173 [==============================] - 81s 466ms/step - loss: 55.2182 - val_loss: 7084.8706\n",
      "Epoch 24/60\n",
      "173/173 [==============================] - 81s 465ms/step - loss: 52.1781 - val_loss: 6631.5068\n",
      "Epoch 25/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 41.2219 - val_loss: 6404.2646\n",
      "Epoch 26/60\n",
      "173/173 [==============================] - 80s 465ms/step - loss: 55.3155 - val_loss: 7143.0869\n",
      "Epoch 27/60\n",
      "173/173 [==============================] - 80s 464ms/step - loss: 40.2231 - val_loss: 7210.3652\n",
      "Epoch 28/60\n",
      "173/173 [==============================] - 80s 465ms/step - loss: 46.0368 - val_loss: 7175.0376\n",
      "Epoch 29/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 46.1763 - val_loss: 7466.1055\n",
      "Epoch 30/60\n",
      "173/173 [==============================] - 80s 464ms/step - loss: 36.8597 - val_loss: 7154.6831\n",
      "Epoch 31/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 47.2100 - val_loss: 7490.4390\n",
      "Epoch 32/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 44.8477 - val_loss: 7539.7954\n",
      "Epoch 33/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 40.0822 - val_loss: 7612.4961\n",
      "Epoch 34/60\n",
      "173/173 [==============================] - 80s 461ms/step - loss: 38.7649 - val_loss: 8154.7300\n",
      "Epoch 35/60\n",
      "173/173 [==============================] - 80s 464ms/step - loss: 36.8057 - val_loss: 7356.9468\n",
      "Epoch 36/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 32.5152 - val_loss: 7256.8501\n",
      "Epoch 37/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 33.7146 - val_loss: 7281.9351\n",
      "Epoch 38/60\n",
      "173/173 [==============================] - 80s 465ms/step - loss: 36.2274 - val_loss: 7087.0957\n",
      "Epoch 39/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 32.5164 - val_loss: 6097.9619\n",
      "Epoch 40/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 33.6914 - val_loss: 6513.5469\n",
      "Epoch 41/60\n",
      "173/173 [==============================] - 80s 464ms/step - loss: 37.5805 - val_loss: 6556.7183\n",
      "Epoch 42/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 38.1818 - val_loss: 7039.8149\n",
      "Epoch 43/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 40.7219 - val_loss: 7510.5547\n",
      "Epoch 44/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 37.9866 - val_loss: 6922.0391\n",
      "Epoch 45/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 28.7851 - val_loss: 6782.5234\n",
      "Epoch 46/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 43.9143 - val_loss: 6964.9331\n",
      "Epoch 47/60\n",
      "173/173 [==============================] - 80s 464ms/step - loss: 30.5365 - val_loss: 6925.1899\n",
      "Epoch 48/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 33.8917 - val_loss: 7374.6963\n",
      "Epoch 49/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 33.5869 - val_loss: 7105.2554\n",
      "Epoch 50/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 27.4363 - val_loss: 6814.6270\n",
      "Epoch 51/60\n",
      "173/173 [==============================] - 80s 461ms/step - loss: 32.9060 - val_loss: 7361.3813\n",
      "Epoch 52/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 31.8635 - val_loss: 7134.9131\n",
      "Epoch 53/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 29.0643 - val_loss: 7399.5942\n",
      "Epoch 54/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 28.6698 - val_loss: 7949.3755\n",
      "Epoch 55/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 26.5363 - val_loss: 6880.7290\n",
      "Epoch 56/60\n",
      "173/173 [==============================] - 80s 461ms/step - loss: 23.9217 - val_loss: 7322.6333\n",
      "Epoch 57/60\n",
      "173/173 [==============================] - 80s 462ms/step - loss: 25.0208 - val_loss: 7094.7070\n",
      "Epoch 58/60\n",
      "173/173 [==============================] - 80s 463ms/step - loss: 27.4146 - val_loss: 7148.6421\n",
      "Epoch 59/60\n",
      "173/173 [==============================] - 80s 461ms/step - loss: 24.1141 - val_loss: 6028.2119\n",
      "Epoch 60/60\n",
      "173/173 [==============================] - 80s 461ms/step - loss: 25.2781 - val_loss: 6512.3164\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_paths), len(train_labels): 53400 53400\n",
      "len(validate_paths), len(validate_labels): 115 115\n",
      "len(test_paths), len(test_labels): 13800 13800\n",
      "len(test_paths_real), len(test_labels_real): 228 228\n",
      "Training...\n",
      "epochs per iteration = 20\n",
      "Epoch 1/60\n",
      "167/167 [==============================] - 104s 623ms/step - loss: 18610.9291 - val_loss: 28525.3594\n",
      "Epoch 2/60\n",
      "167/167 [==============================] - 78s 469ms/step - loss: 16215.5672 - val_loss: 28525.3594\n",
      "Epoch 3/60\n",
      "167/167 [==============================] - 78s 465ms/step - loss: 13477.0871 - val_loss: 28525.3633\n",
      "Epoch 4/60\n",
      "167/167 [==============================] - 77s 462ms/step - loss: 12314.5916 - val_loss: 28525.3691\n",
      "Epoch 5/60\n",
      "167/167 [==============================] - 77s 462ms/step - loss: 11214.2380 - val_loss: 28525.3750\n",
      "Epoch 6/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 9732.0768 - val_loss: 28345.1758\n",
      "Epoch 7/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 8093.8468 - val_loss: 27952.5508\n",
      "Epoch 8/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 7197.9451 - val_loss: 27375.6191\n",
      "Epoch 9/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 6215.2717 - val_loss: 27005.2129\n",
      "Epoch 10/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 4883.8649 - val_loss: 25481.3027\n",
      "Epoch 11/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 4116.5654 - val_loss: 25996.2969\n",
      "Epoch 12/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 3260.6441 - val_loss: 24513.3379\n",
      "Epoch 13/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 2995.9348 - val_loss: 22507.7480\n",
      "Epoch 14/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 2620.5165 - val_loss: 20293.8242\n",
      "Epoch 15/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 1861.1242 - val_loss: 19769.4609\n",
      "Epoch 16/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 1667.7809 - val_loss: 17341.5469\n",
      "Epoch 17/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 1191.0420 - val_loss: 16611.6309\n",
      "Epoch 18/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 928.9729 - val_loss: 12768.9531\n",
      "Epoch 19/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 805.1884 - val_loss: 15084.3984\n",
      "Epoch 20/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 659.3098 - val_loss: 12054.7227\n",
      "Epoch 21/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 430.3996 - val_loss: 11298.2354\n",
      "Epoch 22/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 406.0262 - val_loss: 11833.0625\n",
      "Epoch 23/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 340.7869 - val_loss: 11681.4395\n",
      "Epoch 24/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 289.8709 - val_loss: 10914.8223\n",
      "Epoch 25/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 342.1253 - val_loss: 12186.5635\n",
      "Epoch 26/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 292.9061 - val_loss: 13020.2783\n",
      "Epoch 27/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 270.2043 - val_loss: 11779.8760\n",
      "Epoch 28/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 291.3363 - val_loss: 10437.0420\n",
      "Epoch 29/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 267.9227 - val_loss: 9653.8311\n",
      "Epoch 30/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 268.7925 - val_loss: 8952.1914\n",
      "Epoch 31/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 235.3025 - val_loss: 8634.7842\n",
      "Epoch 32/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 218.0409 - val_loss: 9662.9355\n",
      "Epoch 33/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 247.9960 - val_loss: 9155.9082\n",
      "Epoch 34/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 213.5102 - val_loss: 8755.9434\n",
      "Epoch 35/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 190.7353 - val_loss: 9193.2422\n",
      "Epoch 36/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 200.4477 - val_loss: 8963.7539\n",
      "Epoch 37/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 185.4844 - val_loss: 7450.8452\n",
      "Epoch 38/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 201.1450 - val_loss: 7995.7617\n",
      "Epoch 39/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 157.4636 - val_loss: 7047.7671\n",
      "Epoch 40/60\n",
      "167/167 [==============================] - 77s 462ms/step - loss: 178.3969 - val_loss: 7699.4727\n",
      "Epoch 41/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 203.8613 - val_loss: 7860.9897\n",
      "Epoch 42/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 148.6276 - val_loss: 5892.4575\n",
      "Epoch 43/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 150.7889 - val_loss: 8253.5889\n",
      "Epoch 44/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 146.7517 - val_loss: 6906.9219\n",
      "Epoch 45/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 157.3095 - val_loss: 8282.2344\n",
      "Epoch 46/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 129.0195 - val_loss: 7526.0205\n",
      "Epoch 47/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 174.3296 - val_loss: 7762.6987\n",
      "Epoch 48/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 163.4603 - val_loss: 6610.4434\n",
      "Epoch 49/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 167.4274 - val_loss: 6172.0522\n",
      "Epoch 50/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 175.7421 - val_loss: 5845.0542\n",
      "Epoch 51/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 141.8211 - val_loss: 4528.0396\n",
      "Epoch 52/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 137.8699 - val_loss: 14258.4424\n",
      "Epoch 53/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 166.3919 - val_loss: 6915.9668\n",
      "Epoch 54/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 140.5282 - val_loss: 6207.6904\n",
      "Epoch 55/60\n",
      "167/167 [==============================] - 76s 458ms/step - loss: 131.7350 - val_loss: 5353.5981\n",
      "Epoch 56/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 120.5325 - val_loss: 5786.0029\n",
      "Epoch 57/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 121.7365 - val_loss: 5511.8345\n",
      "Epoch 58/60\n",
      "167/167 [==============================] - 76s 457ms/step - loss: 141.9832 - val_loss: 5517.6807\n",
      "Epoch 59/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 108.7825 - val_loss: 4728.4229\n",
      "Epoch 60/60\n",
      "167/167 [==============================] - 76s 456ms/step - loss: 118.6765 - val_loss: 4387.2715\n",
      "Epoch 1/60\n",
      "167/167 [==============================] - 104s 624ms/step - loss: 93.4771 - val_loss: 4695.3105\n",
      "Epoch 2/60\n",
      "167/167 [==============================] - 78s 466ms/step - loss: 80.9895 - val_loss: 4547.2510\n",
      "Epoch 3/60\n",
      "167/167 [==============================] - 77s 464ms/step - loss: 83.9966 - val_loss: 4483.2573\n",
      "Epoch 4/60\n",
      "167/167 [==============================] - 77s 462ms/step - loss: 75.2463 - val_loss: 4518.3594\n",
      "Epoch 5/60\n",
      "167/167 [==============================] - 77s 461ms/step - loss: 81.0516 - val_loss: 4510.4316\n",
      "Epoch 6/60\n",
      "167/167 [==============================] - 77s 461ms/step - loss: 74.3969 - val_loss: 4768.0508\n",
      "Epoch 7/60\n",
      "167/167 [==============================] - 77s 461ms/step - loss: 74.2094 - val_loss: 4696.3159\n",
      "Epoch 8/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 65.6509 - val_loss: 4267.0850\n",
      "Epoch 9/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 71.9859 - val_loss: 4262.0571\n",
      "Epoch 10/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 69.8894 - val_loss: 4275.3491\n",
      "Epoch 11/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 67.7405 - val_loss: 4330.5957\n",
      "Epoch 12/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 59.5836 - val_loss: 4166.9985\n",
      "Epoch 13/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 78.9678 - val_loss: 3991.7942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 64.2376 - val_loss: 4055.4736\n",
      "Epoch 15/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 64.4438 - val_loss: 3883.0425\n",
      "Epoch 16/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 54.2029 - val_loss: 3888.3489\n",
      "Epoch 17/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 56.3510 - val_loss: 3929.7549\n",
      "Epoch 18/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 55.9988 - val_loss: 3833.0754\n",
      "Epoch 19/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 60.2943 - val_loss: 3861.3411\n",
      "Epoch 20/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 55.4771 - val_loss: 3752.5793\n",
      "Epoch 21/60\n",
      "167/167 [==============================] - 77s 458ms/step - loss: 70.6467 - val_loss: 3582.3572\n",
      "Epoch 22/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 57.2831 - val_loss: 3477.2900\n",
      "Epoch 23/60\n",
      "167/167 [==============================] - 78s 466ms/step - loss: 61.2934 - val_loss: 3542.7722\n",
      "Epoch 24/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 53.9223 - val_loss: 3554.1553\n",
      "Epoch 25/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 61.5381 - val_loss: 3482.9563\n",
      "Epoch 26/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 55.1906 - val_loss: 3702.1418\n",
      "Epoch 27/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 51.9511 - val_loss: 3657.2651\n",
      "Epoch 28/60\n",
      "167/167 [==============================] - 77s 463ms/step - loss: 68.1723 - val_loss: 3432.6206\n",
      "Epoch 29/60\n",
      "167/167 [==============================] - 79s 476ms/step - loss: 58.4408 - val_loss: 3242.5051\n",
      "Epoch 30/60\n",
      "167/167 [==============================] - 80s 480ms/step - loss: 59.5565 - val_loss: 3327.1670\n",
      "Epoch 31/60\n",
      "167/167 [==============================] - 84s 506ms/step - loss: 54.2678 - val_loss: 3324.0078\n",
      "Epoch 32/60\n",
      "167/167 [==============================] - 84s 501ms/step - loss: 55.2112 - val_loss: 3495.4597\n",
      "Epoch 33/60\n",
      "167/167 [==============================] - 83s 498ms/step - loss: 53.7916 - val_loss: 3313.5906\n",
      "Epoch 34/60\n",
      "167/167 [==============================] - 85s 510ms/step - loss: 49.3761 - val_loss: 3368.9343\n",
      "Epoch 35/60\n",
      "167/167 [==============================] - 84s 502ms/step - loss: 44.1039 - val_loss: 3263.4219\n",
      "Epoch 36/60\n",
      "167/167 [==============================] - 78s 468ms/step - loss: 46.7184 - val_loss: 3079.5674\n",
      "Epoch 37/60\n",
      "167/167 [==============================] - 81s 487ms/step - loss: 38.5415 - val_loss: 3078.0403\n",
      "Epoch 38/60\n",
      "167/167 [==============================] - 82s 488ms/step - loss: 44.3074 - val_loss: 3109.9172\n",
      "Epoch 39/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 36.6772 - val_loss: 3022.1196\n",
      "Epoch 40/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 36.9720 - val_loss: 3035.1152\n",
      "Epoch 41/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 53.2570 - val_loss: 3012.6526\n",
      "Epoch 42/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 41.2802 - val_loss: 2951.6184\n",
      "Epoch 43/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 46.1026 - val_loss: 3075.3250\n",
      "Epoch 44/60\n",
      "167/167 [==============================] - 77s 459ms/step - loss: 40.4407 - val_loss: 3053.3235\n",
      "Epoch 45/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 45.8074 - val_loss: 3086.3276\n",
      "Epoch 46/60\n",
      "167/167 [==============================] - 77s 460ms/step - loss: 40.0859 - val_loss: 3237.6313\n",
      "Epoch 47/60\n",
      "167/167 [==============================] - 78s 465ms/step - loss: 37.2674 - val_loss: 3247.3992\n",
      "Epoch 48/60\n",
      "167/167 [==============================] - 78s 468ms/step - loss: 53.0589 - val_loss: 3131.8643\n",
      "Epoch 49/60\n",
      "167/167 [==============================] - 79s 475ms/step - loss: 43.9184 - val_loss: 3022.5564\n",
      "Epoch 50/60\n",
      "167/167 [==============================] - 79s 476ms/step - loss: 45.8002 - val_loss: 2991.9919\n",
      "Epoch 51/60\n",
      "167/167 [==============================] - 80s 477ms/step - loss: 39.6283 - val_loss: 2956.3894\n",
      "Epoch 52/60\n",
      "162/167 [============================>.] - ETA: 2s - loss: 40.8172"
     ]
    }
   ],
   "source": [
    "# Initial models\n",
    "if not os.path.exists(initial_hdf5_path):\n",
    "    if not os.path.exists(initial_model_dir):\n",
    "        os.makedirs(initial_model_dir)\n",
    "    if net == 'vgg19':\n",
    "        base_model = VGG19(weights='imagenet', include_top=False)\n",
    "    elif net == 'inceptionV4':\n",
    "        base_model = inception_v4(weights='imagenet', include_top=False, input_shape=((890 - 95)//6, 1920//6, 3))\n",
    "    elif net == 'densenet201':\n",
    "        base_model = DenseNet201(weights='imagenet', include_top=False)\n",
    "    elif net == 'resnet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='relu')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x, name=net)\n",
    "    with open(initial_json_path, 'w') as fout:\n",
    "        fout.write(model.to_json())\n",
    "    model.save_weights(initial_hdf5_path)\n",
    "# Data import\n",
    "with open(initial_json_path, 'r') as fout:\n",
    "    model = model_from_json(fout.read())\n",
    "for idx_validate in range(idx_start, idx_end+1):\n",
    "\n",
    "    (train_paths, train_labels, validate_paths, validate_labels, test_paths, test_labels,\n",
    "     test_paths_real, test_labels_real, test_paths_for_test, test_labels_for_test) = get_data(idx_validate)\n",
    "    print('len(train_paths), len(train_labels):', len(train_paths), len(train_labels))\n",
    "    print('len(validate_paths), len(validate_labels):', len(validate_paths), len(validate_labels))\n",
    "    print('len(test_paths), len(test_labels):', len(test_paths), len(test_labels))\n",
    "    print('len(test_paths_real), len(test_labels_real):', len(test_paths_real), len(test_labels_real))\n",
    "\n",
    "    # Train\n",
    "    model.load_weights(initial_hdf5_path)\n",
    "    optimizer_1 = Adam(lr=1e-4)\n",
    "    optimizer_2 = Adam(lr=1e-5)\n",
    "\n",
    "    model.compile(optimizer=optimizer_1, loss=LOSS.lower())\n",
    "\n",
    "    saver_1 = SaveModelOnMSE_1(idx_validate)\n",
    "    saver_2 = SaveModelOnMSE_2(idx_validate)\n",
    "    if not os.path.exists(os.path.join('weights_new', LOSS, net, 'Test_set_{}'.format(idx_validate))):\n",
    "        os.makedirs(os.path.join('weights_new', LOSS, net, 'Test_set_{}'.format(idx_validate)))\n",
    "    print('Training...')\n",
    "    batch_size_train = 16\n",
    "    # validation_interval = 3000\n",
    "    # epochs_per_iteration = math.ceil(len(train_labels) / validation_interval)\n",
    "    epochs_per_iteration = 20\n",
    "    validation_interval = math.ceil(len(train_labels) / epochs_per_iteration)\n",
    "    batch_size_validate = math.floor(len(validate_labels)/1)\n",
    "    print('epochs per iteration =', epochs_per_iteration)\n",
    "    train_generator = generate_generator(train_paths, train_labels, batch_size=batch_size_train, reverse=True)\n",
    "    validate_generator = generate_generator(validate_paths, validate_labels, batch_size=batch_size_validate)\n",
    "    history_1 = model.fit_generator(\n",
    "        train_generator, steps_per_epoch=math.ceil(validation_interval/batch_size_train),\n",
    "        epochs=epochs_per_iteration*3,\n",
    "        validation_data=validate_generator, validation_steps=1,\n",
    "        verbose=1, callbacks=[saver_1],\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    model.compile(optimizer=optimizer_2, loss=LOSS.lower())\n",
    "    history_2 = model.fit_generator(\n",
    "        train_generator, steps_per_epoch=math.ceil(validation_interval/batch_size_train),\n",
    "        epochs=epochs_per_iteration*3,\n",
    "        validation_data=validate_generator, validation_steps=1,\n",
    "        verbose=1, callbacks=[saver_2],\n",
    "        use_multiprocessing=True\n",
    "    )\n",
    "    vl, l = history_1.history['val_loss']+history_2.history['val_loss'], history_1.history['loss']+history_2.history['loss']\n",
    "    if not os.path.exists(os.path.join('loss_new', LOSS, net, 'Test_set_{}'.format(idx_validate))):\n",
    "        os.makedirs(os.path.join('loss_new', LOSS, net, 'Test_set_{}'.format(idx_validate)))\n",
    "    np.savetxt(os.path.join('loss_new', LOSS, net, 'Test_set_{}'.format(idx_validate), '{}_val.txt'.format(LOSS)), vl)\n",
    "    np.savetxt(os.path.join('loss_new', LOSS, net, 'Test_set_{}'.format(idx_validate), '{}_train.txt'.format(LOSS)), l)\n",
    "    plt.plot(vl, 'r')\n",
    "    plt.plot(l, 'b')\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx_validate in range(idx_start, idx_end+1):\n",
    "    # Predict and Save\n",
    "    (train_paths, train_labels, validate_paths, validate_labels, test_paths, test_labels,\n",
    "     test_paths_real, test_labels_real, test_paths_for_test, test_labels_for_test) = get_data(idx_validate)\n",
    "    src_files = 'weights_new/{}/{}/*.hdf5'.format(LOSS, net)\n",
    "    dst_dir = 'weights_new/{}/{}/Test_set_{}'.format(LOSS, net, idx_validate)\n",
    "    # os.system(\"mv {} {}\".format(src_files, dst_dir))\n",
    "    # with open(initial_json_path, 'r') as fout:\n",
    "    #     model = model_from_json(fout.read())\n",
    "    models = os.listdir(dst_dir)\n",
    "    models = sorted(models, key=lambda x: int(x.split('epoch')[1].split('_')[0]))\n",
    "    losses = []\n",
    "    epochs = []\n",
    "    for i in models:\n",
    "        losses.append(float(i.split('_')[-1][len(LOSS):-5]))\n",
    "        epochs.append(int(i.split('epoch')[-1].split('_')[0]))\n",
    "\n",
    "    print('{}-th, len(losses): {}'.format(idx_validate, len(losses)))\n",
    "    for idx, loss in enumerate(losses):\n",
    "        if idx < 0:\n",
    "            continue\n",
    "        if idx > 200:\n",
    "            break\n",
    "        print(idx, 'loading', net+'_{}'.format(LOSS)+str(loss)+'.hdf5', end=', ')\n",
    "        weights_file_path = os.path.join('weights_new', LOSS, net, 'Test_set_{}'.format(idx_validate), net+'_{}_epoch'.format(LOSS)+str(epochs[idx])+'_{}'.format(LOSS)+str(loss)+'.hdf5')\n",
    "        model.load_weights(weights_file_path)\n",
    "        test_epoch = len(test_labels_for_test) // 50\n",
    "        batch_size_for_test = len(test_labels_for_test) // test_epoch\n",
    "        test_generator = generate_generator(test_paths_for_test, test_labels_for_test, batch_size=batch_size_for_test)\n",
    "        preds = []\n",
    "        y_vals = []\n",
    "        print('Generating ', end='')\n",
    "        for i in range(test_epoch)[:]:\n",
    "            if i % 10 == 0:\n",
    "                print('{}/{}'.format(i+1, test_epoch), end=', ')\n",
    "            x_val, y_val = test_generator.__next__()\n",
    "            preds += np.squeeze(model.predict(x_val)).tolist()\n",
    "            y_vals += y_val.tolist()\n",
    "        preds = np.asarray(preds)\n",
    "        y_vals = np.asarray(y_vals).astype(np.float)\n",
    "        MSE, MAE, MAPE = round(np.mean(np.square(preds-y_vals)), 3), round(np.mean(np.abs(preds-y_vals)), 3), round(100 * np.mean(np.abs(preds - y_vals) / y_vals), 3)\n",
    "        print('MAE={}, MSE={}, MAPE={}.'.format(MAE, MSE, MAPE))\n",
    "        path_SI = os.path.join('preds_new', LOSS, net, 'Test_set_{}'.format(idx_validate), 'Subject_Interpolation')\n",
    "        if not os.path.exists(path_SI):\n",
    "            os.makedirs(path_SI)\n",
    "        prediction_save_path = os.path.join(path_SI, net+'_{}_epoch'.format(LOSS)+str(epochs[idx])+'_MAPE{}_MAE{}_MSE{}.txt'.format(str(MAPE)[:str(MAE).find('.')+2], str(MAE)[:str(MAE).find('.')+2], str(MSE)[:str(MSE).find('.')+2]))\n",
    "        np.savetxt(prediction_save_path,  preds)\n",
    "        if idx % 100 == 60:\n",
    "            plt.plot(preds); plt.plot(y_vals); plt.legend(['pd', 'lbl']); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test real data\n",
    "# with open(initial_json_path, 'r') as fout:\n",
    "#     model = model_from_json(fout.read())\n",
    "for camera in range(idx_start, idx_end+1):\n",
    "    vis = scio.loadmat('./data/Subject_Measured_Vis.mat')\n",
    "    vis_keys_median = [i for i in vis.keys() if 'dian' in i][camera-1]\n",
    "    label_for_test = []\n",
    "    label_for_test = np.squeeze(vis[vis_keys_median]).tolist()\n",
    "\n",
    "    path_for_test = []\n",
    "    camera_dir = './data/point_NUPT/'\n",
    "    camera_path = os.path.join(camera_dir, sorted(os.listdir(camera_dir), key=lambda x: int(x.split('_')[0]))[camera-1])\n",
    "    for img_path in sorted(os.listdir(camera_path), key=lambda x: int(x.split('_')[-1].rstrip('.jpg'))):\n",
    "        path_for_test.append(os.path.join(camera_path, img_path))\n",
    "    label_for_test, path_for_test = np.squeeze(np.array(label_for_test)), np.squeeze(np.array(path_for_test))\n",
    "    print(label_for_test.shape, path_for_test.shape)\n",
    "\n",
    "    dst_dir = 'weights_new/{}/{}/Test_set_{}'.format(LOSS, net, camera)\n",
    "    models = os.listdir(dst_dir)\n",
    "    models = sorted(models, key=lambda x: int(x.split('epoch')[1].split('_')[0]))\n",
    "    losses = []\n",
    "    epochs = []\n",
    "    for i in models:\n",
    "        losses.append(float(i.split('_')[-1][len(LOSS):-5]))\n",
    "        epochs.append(int(i.split('epoch')[-1].split('_')[0]))\n",
    "\n",
    "    print('len(losses):', len(losses))\n",
    "    prediction_save_dir = os.path.join('preds_new', LOSS, net, 'Test_set_{}'.format(camera), 'Subject')\n",
    "    if not os.path.exists(prediction_save_dir):\n",
    "        os.makedirs(prediction_save_dir)\n",
    "    for idx, loss in enumerate(losses):\n",
    "        if idx < 0:\n",
    "            continue\n",
    "        if idx > 200:\n",
    "            break\n",
    "        weights_file_path = os.path.join('weights_new', LOSS, net, 'Test_set_{}'.format(camera), net+'_{}_epoch'.format(LOSS)+str(epochs[idx])+'_{}'.format(LOSS)+str(loss)+'.hdf5')\n",
    "        print(idx, 'loading {}'.format(weights_file_path), end=', ')\n",
    "        test_generator = generate_generator(path_for_test, label_for_test, batch_size=label_for_test.shape[0])\n",
    "        model.load_weights(weights_file_path)\n",
    "        img_for_test = test_generator.__next__()[0]\n",
    "        preds = np.squeeze(model.predict(img_for_test))\n",
    "        MSE, MAE, MAPE = round(np.mean(np.square(preds-label_for_test)), 3), round(np.mean(np.abs(preds-label_for_test)), 3), round(100 * np.mean(np.abs(preds - label_for_test) / label_for_test), 3)\n",
    "        print('MAPE={}, MAE={}, MSE={}'.format(MAPE, MAE, MSE))\n",
    "        prediction_save_path = net+'_{}_epoch'.format(LOSS)+str(epochs[idx])+'_MAPE{}_MAE{}_MSE{}.txt'.format(str(MAPE)[:str(MAE).find('.')+2], str(MAE)[:str(MAE).find('.')+2], str(MSE)[:str(MSE).find('.')+2])\n",
    "        np.savetxt(os.path.join(prediction_save_dir, prediction_save_path), preds)\n",
    "        if idx % 50 == 0:\n",
    "            plt.plot(preds); plt.plot(label_for_test); plt.legend(['pd', 'lbl']); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
